{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saipragna25/deep-learning-assignment--2/blob/main/DLA2bPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_O7EYmr7Zjk"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar vector multiplication\n",
        "\n",
        "a = torch.rand(1)\n",
        "b = torch.rand(4, 6)\n",
        "c = torch.einsum('i, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y1LUGch7wgr",
        "outputId": "bc1fa0c8-0fa4-4058-875f-a75a1f4881c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2056])\n",
            "tensor([[0.7847, 0.3242, 0.8594, 0.7294, 0.6756, 0.7735],\n",
            "        [0.5987, 0.3935, 0.2479, 0.9725, 0.9094, 0.9963],\n",
            "        [0.5231, 0.2006, 0.1014, 0.3237, 0.6816, 0.9045],\n",
            "        [0.0908, 0.0197, 0.6833, 0.1385, 0.8535, 0.7276]])\n",
            "tensor([[0.1613, 0.0666, 0.1767, 0.1499, 0.1389, 0.1590],\n",
            "        [0.1231, 0.0809, 0.0510, 0.1999, 0.1869, 0.2048],\n",
            "        [0.1075, 0.0412, 0.0209, 0.0665, 0.1401, 0.1859],\n",
            "        [0.0187, 0.0040, 0.1405, 0.0285, 0.1755, 0.1496]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector vector multiplication\n",
        "\n",
        "a = torch.rand(2, 4)\n",
        "b = torch.rand(4, 6)\n",
        "c= torch.einsum('ij, jk -> ik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ4CMTM_755g",
        "outputId": "695d2d7d-1302-4228-f80f-37d2fe0d17f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8073, 0.7092, 0.7345, 0.7350],\n",
            "        [0.0397, 0.7958, 0.2273, 0.9339]])\n",
            "tensor([[0.2080, 0.8416, 0.7013, 0.9441, 0.0336, 0.3628],\n",
            "        [0.7711, 0.7964, 0.7351, 0.8595, 0.4359, 0.4202],\n",
            "        [0.5925, 0.1833, 0.2533, 0.9173, 0.0815, 0.5937],\n",
            "        [0.6564, 0.3552, 0.8219, 0.9124, 0.4994, 0.2953]])\n",
            "tensor([[1.6325, 1.6400, 1.8777, 2.7161, 0.7632, 1.2440],\n",
            "        [1.3697, 1.0406, 1.4380, 1.7821, 0.8332, 0.7596]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer product\n",
        "\n",
        "a = torch.arange(5)\n",
        "b = torch.arange(3, 6)  \n",
        "op= torch.einsum('i,j -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(op)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-49ddgB8Pnz",
        "outputId": "7dc9e271-24c7-4121-c6d7-7805b37edd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n",
            "tensor([3, 4, 5])\n",
            "tensor([[ 0,  0,  0],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  8, 10],\n",
            "        [ 9, 12, 15],\n",
            "        [12, 16, 20]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar dot product\n",
        "\n",
        "a = torch.arange(9).reshape(3, 3)\n",
        "b = torch.arange(6).reshape(3, 2)\n",
        "sp = torch.einsum('ij, jk ->', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(sp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ddVdB38UIJ",
        "outputId": "7f9ae4a8-d379-4b75-ab41-4ad0c35222d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor(204)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadamard product\n",
        "\n",
        "a = torch.arange(8).reshape(2, 4)\n",
        "b = torch.arange(4, 12).reshape(2, 4)\n",
        "hp = torch.einsum('ij, ij -> ij', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(hp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TscM27338qr9",
        "outputId": "6d005939-e930-4674-ac77-80677eeff1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  5, 12, 21],\n",
            "        [32, 45, 60, 77]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch matrix multiplication\n",
        "\n",
        "a = torch.randn(3, 3, 5)\n",
        "b = torch.randn(3, 5, 2)\n",
        "batch_matrix_mul = torch.einsum('bij, bjk -> bik', [a, b])\n",
        "print(a)\n",
        "print(b)\n",
        "print(batch_matrix_mul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgvmyiWD86Ck",
        "outputId": "065658fe-0efb-498c-93c7-5db9fa4ca253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4476, -1.0997, -1.8756, -0.1006, -0.5556],\n",
            "         [ 0.1199,  0.3324, -1.1917,  0.0031, -1.3100],\n",
            "         [-0.8157, -0.0212, -1.0283, -0.3902,  0.4457]],\n",
            "\n",
            "        [[-0.9156, -0.6302, -0.8163, -0.3021, -0.6447],\n",
            "         [ 0.7042, -0.5001, -0.3725,  0.8084, -2.6468],\n",
            "         [ 1.3482,  0.0910, -0.5790,  1.4507,  0.1389]],\n",
            "\n",
            "        [[ 0.5679,  1.0392,  1.2311,  0.2235, -0.8959],\n",
            "         [-0.2645, -1.2623, -0.2102,  0.8275, -0.5388],\n",
            "         [-2.1786, -0.4738, -0.0850, -0.6662, -1.3504]]])\n",
            "tensor([[[ 0.3192,  0.2399],\n",
            "         [ 0.2602,  0.4140],\n",
            "         [ 0.0138, -2.1651],\n",
            "         [-2.3568,  0.5865],\n",
            "         [-0.0797, -0.2870]],\n",
            "\n",
            "        [[ 0.4947, -0.2482],\n",
            "         [ 1.1957, -0.6888],\n",
            "         [ 0.4933, -1.7492],\n",
            "         [ 0.7893, -0.0767],\n",
            "         [-0.0727,  0.2591]],\n",
            "\n",
            "        [[ 0.6484,  0.5163],\n",
            "         [ 0.2918, -1.8880],\n",
            "         [ 0.0317, -0.2934],\n",
            "         [-1.3810,  0.2712],\n",
            "         [ 0.5550,  1.5976]]])\n",
            "tensor([[[-0.1735,  3.5988],\n",
            "         [ 0.2054,  3.1244],\n",
            "         [ 0.6042,  1.6652]],\n",
            "\n",
            "        [[-1.8008,  1.9455],\n",
            "         [ 0.3972,  0.0735],\n",
            "         [ 1.6249,  0.5402]],\n",
            "\n",
            "        [[-0.0953, -3.4007],\n",
            "         [-1.9884,  1.6719],\n",
            "         [-1.3830, -2.5434]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor reduction\n",
        "\n",
        "a = torch.randn(2, 3, 5, 7)\n",
        "b = torch.randn(4, 1, 3, 11, 5)\n",
        "tensor_reduction = torch.einsum('pqrs, tuqvr -> pstuv', [a, b])\n",
        "print(a.shape, b.shape, tensor_reduction.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPocnSCH8_fZ",
        "outputId": "43245dcf-7b7e-4733-b9d7-d6bd2ed5b061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 5, 7]) torch.Size([4, 1, 3, 11, 5]) torch.Size([2, 7, 4, 1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "\n",
        "a = torch.arange(8).reshape(4, 2)\n",
        "transpose = torch.einsum('ij -> ji', [a])\n",
        "print(a)\n",
        "print(transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StmTS9VZ9Ce8",
        "outputId": "8e54a76b-c45f-4fae-ec6d-c82221f17eeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5],\n",
            "        [6, 7]])\n",
            "tensor([[0, 2, 4, 6],\n",
            "        [1, 3, 5, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilinear transformation\n",
        "\n",
        "a = torch.randn(2, 3)\n",
        "b = torch.randn(3, 3, 4)\n",
        "c = torch.randn(2, 4)\n",
        "bilinear_transform = torch.einsum('ik, jkl, il -> ij', [a, b, c])\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(bilinear_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyQ27_eS9Fxt",
        "outputId": "5ba30263-bfc5-48d8-c908-18d32b62f46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6670, -0.4857,  0.1110],\n",
            "        [-1.1271, -1.3712, -0.7412]])\n",
            "tensor([[[ 1.0649, -0.0591, -0.6925, -0.5121],\n",
            "         [-1.0292, -0.5268,  1.7538, -0.7419],\n",
            "         [-0.0800, -0.5668,  1.3868, -1.1612]],\n",
            "\n",
            "        [[ 0.0969,  0.5483, -0.2376,  0.0891],\n",
            "         [ 2.0558,  0.7923, -0.1878,  0.4751],\n",
            "         [ 0.3288, -0.2456, -0.1581,  0.9347]],\n",
            "\n",
            "        [[-1.7431,  1.2076,  0.6249,  1.4328],\n",
            "         [ 0.7649,  0.2961,  1.5144, -0.1632],\n",
            "         [-0.6044, -0.0875,  0.8127,  0.3896]]])\n",
            "tensor([[-1.1190, -0.6122,  0.1096,  1.6205],\n",
            "        [-0.0770,  0.5838,  0.3097,  0.0342]])\n",
            "tensor([[ 1.0058,  1.3481, -1.6897],\n",
            "        [-0.0524, -0.4950, -2.2038]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention\n",
        "\n",
        "def random_tensors(shape, num=1, requires_grad=False):\n",
        "  tensors = [torch.randn(shape, requires_grad=requires_grad) for i in range(0, num)]\n",
        "  return tensors[0] if num == 1 else tensors\n",
        "\n",
        "# Parameters\n",
        "# [hidden_dimension]\n",
        "bM, br, w = random_tensors([7], num=3, requires_grad=True)\n",
        "# [hidden_dimension x hidden_dimension]\n",
        "WY, Wh, Wr, Wt = random_tensors([7, 7], num=4, requires_grad=True)\n",
        "\n",
        "def attention(Y, ht, rt1):\n",
        "  # [batch_size x hidden_dimension] \n",
        "  tmp = torch.einsum('ik, kl -> il', [ht, Wh]) + torch.einsum('ik, kl -> il', [rt1, Wr])\n",
        "\n",
        "  Mt = torch.tanh(torch.einsum('ijk, kl -> ijl', [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  \n",
        "  # [batch_size x sequence_length]\n",
        "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w])) \n",
        "  \n",
        "  # [batch_size x hidden_dimension]\n",
        "  rt = torch.einsum('ijk, ij -> ik', [Y, at]) + torch.tanh(torch.einsum('ij, jk -> ik', [rt1, Wt]) + br)\n",
        "  \n",
        "  return rt, at\n",
        "\n",
        "# Inputs - [batch_size x sequence_length x hidden_dimension]\n",
        "Y = torch.randn(3,5,7)\n",
        "# [batch_size x hidden_dimension]\n",
        "ht, rt1 = random_tensors([3, 7], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "\n",
        "print(at)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1hndqmL9Mi-",
        "outputId": "6f04c989-c084-450f-eeda-bf6bda3efd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0373, 0.0904, 0.5381, 0.0146, 0.3196],\n",
            "        [0.3684, 0.1695, 0.0401, 0.3515, 0.0705],\n",
            "        [0.3472, 0.0074, 0.0200, 0.2715, 0.3538]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-0f495568e4dc>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  at = torch.nn.functional.softmax(torch.einsum('ijk, k -> ij', [Mt, w]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treeqn\n",
        "\n",
        "def transition(zl):\n",
        "  # [batch_size x num_actions x hidden_dimension]\n",
        "  return zl.unsqueeze(1) + torch.tanh(torch.einsum('bk, aki -> bai', [zl, W]) + b)\n",
        "\n",
        "# Inputs - [batch_size x hidden_dimension]\n",
        "zl = torch.randn(2, 3)\n",
        "# Parameters - [num_actions x hidden_dimension]\n",
        "b = torch.randn(5, 3)\n",
        "# Actions - [num_actions x hidden_dimension x hidden_dimension]\n",
        "W = torch.randn(5, 3, 3)\n",
        "\n",
        "transition(zl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmqtU8_B9PkR",
        "outputId": "3750feb9-18eb-4d35-8c40-b014185f6fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.6091, -0.9768, -0.0382],\n",
              "         [ 0.7039, -0.6952,  0.9831],\n",
              "         [ 1.4307,  0.7482,  1.3725],\n",
              "         [ 0.1971,  0.2918,  1.1721],\n",
              "         [ 0.1041, -0.6191,  0.7931]],\n",
              "\n",
              "        [[ 0.8237, -0.0585, -0.1657],\n",
              "         [-0.8563,  1.5082, -0.2654],\n",
              "         [-0.2914,  0.4693,  1.2502],\n",
              "         [-0.4363,  1.4290,  0.9658],\n",
              "         [-1.0381, -0.2776,  0.7747]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}